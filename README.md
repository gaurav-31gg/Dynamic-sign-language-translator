# Dynamic-sign-language-translator
A real-time sign language recognition system that uses a CNN-based model for recognizing hand gestures via a webcam. Built using TensorFlow.js, MobileNet, and KNN, this project helps bridge the communication gap for people using sign language.
Features
âœ… Real-time hand gesture recognition using a webcam
âœ… Runs in the browser (no additional installation required)
âœ… Uses MobileNet for efficient feature extraction
âœ… K-Nearest Neighbors (KNN) for gesture classification
âœ… Interactive and user-friendly UI
Technologies Used
Frontend: HTML, CSS, JavaScript
Machine Learning: TensorFlow.js, MobileNet, KNN
Image Processing: OpenCV.js, HSV color space

How It Works
Webcam Activation ğŸ¥

The system captures live images of hand gestures using OpenCV.js.
The background is removed using the HSV color space for better detection.
Feature Extraction ğŸ§ 

MobileNet, a lightweight deep learning model, extracts important features from the hand gesture.
Gesture Classification ğŸ”

The K-Nearest Neighbors (KNN) algorithm classifies the hand gesture by comparing it with stored samples.
Display Recognized Gesture âœ…

The recognized gesture is displayed as text in the frontend UI.

ğŸš€ How to Run the Project
1ï¸âƒ£ Open the Project in a Browser
Simply open index.html in a browser (Chrome recommended).

2ï¸âƒ£Allow Camera Access
The website will request webcam permissions for real-time gesture recognition.

Future Improvements
ğŸš€ Expand Gesture Dataset to support more signs
ğŸ“± Develop a Mobile App for better accessibility
ğŸ”  Integrate Text-to-Speech for real-time audio output


