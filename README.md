# Dynamic-sign-language-translator
A real-time sign language recognition system that uses a CNN-based model for recognizing hand gestures via a webcam. Built using TensorFlow.js, MobileNet, and KNN, this project helps bridge the communication gap for people using sign language.

ğŸ› ï¸ Features
âœ… Real-time hand gesture recognition using a webcam
âœ… Runs in the browser (no additional installation required)
âœ… Uses MobileNet for efficient feature extraction
âœ… K-Nearest Neighbors (KNN) for gesture classification
âœ… Interactive and user-friendly UI

ğŸ“Œ Technologies Used
Frontend: HTML, CSS, JavaScript
Machine Learning: TensorFlow.js, MobileNet, KNN
Image Processing: OpenCV.js, HSV color space
ğŸ“– How It Works
Webcam Activation ğŸ¥

The system captures live images of hand gestures using OpenCV.js.
The background is removed using the HSV color space for better detection.
Feature Extraction ğŸ§ 

MobileNet, a lightweight deep learning model, extracts important features from the hand gesture.
Gesture Classification ğŸ”

The K-Nearest Neighbors (KNN) algorithm classifies the hand gesture by comparing it with stored samples.
Display Recognized Gesture âœ…

The recognized gesture is displayed as text in the frontend UI.
ğŸš€ How to Run the Project
1ï¸âƒ£ Clone the Repository
bash
Copy
Edit
git clone https://github.com/your-username/sign-language-recognition.git
cd sign-language-recognition
2ï¸âƒ£ Open the Project in a Browser
Simply open index.html in a browser (Chrome recommended).

3ï¸âƒ£ Allow Camera Access
The website will request webcam permissions for real-time gesture recognition.

ğŸ› ï¸ Future Improvements
ğŸš€ Expand Gesture Dataset to support more signs
ğŸ“± Develop a Mobile App for better accessibility
ğŸ”  Integrate Text-to-Speech for real-time audio output



